{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size=1000\n",
    "test_frac = 0.1\n",
    "input_size = 16\n",
    "output_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoremaker():\n",
    "    #empty scores represent the subjects that the student doesn't take\n",
    "    emptyScores = np.random.randint(low = 0, high = output_size, size=(3))        \n",
    "    \n",
    "    #randomly generate 2 sets of results. For different schools, scale the result accordingly\n",
    "    scores = np.random.randint(low = 50, high = 90, size=(output_size))\n",
    "    scores = scores + np.random.randint(low = -10, high = 10, size=(output_size))\n",
    "    scores2 = np.random.randint(low = 50, high = 90, size=(output_size))\n",
    "    scores2 = scores2 + np.random.randint(low = -10, high = 10, size=(output_size))\n",
    "    \n",
    "    #generate 2 values, 1 for humanities-related activities and one for science activities. More activities = higher score\n",
    "    activities = np.random.randint(low = 0, high = 10, size = (2))\n",
    "    \n",
    "    #generate fake labels for each listing.\n",
    "    scoreLabels = (scores + scores2) / 2\n",
    "    \n",
    "    #add activity score to labels for each subject\n",
    "    for i in range(output_size):\n",
    "        if(i < 4): scoreLabels[i] += activities[0]\n",
    "        else: scoreLabels[i] += activities[1]\n",
    "\n",
    "    scoreLabels = (scoreLabels - 40) / 60\n",
    "    \n",
    "    #make subjects empty\n",
    "    for i in emptyScores:\n",
    "        scores[i] = 0\n",
    "        scores2[i] = 0\n",
    "        scoreLabels[i] = 0\n",
    "        \n",
    "    return scoreLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataMaker():\n",
    "    #make some fake scores and use signed difference as a feature\n",
    "    teacherscores = scoremaker()\n",
    "    studentscores = scoremaker()\n",
    "    scoresdiff = teacherscores - studentscores\n",
    "    \n",
    "    #label is closely related to how much better a teacher is than a student.\n",
    "    #also have to penalize for being too good.\n",
    "    #right now I'm using a piecewise method to penalize:\n",
    "    #if  diff > 0.5 then diff = 1 - 0.5\n",
    "    label = np.array(scoresdiff)\n",
    "    \n",
    "    for i in range(output_size):\n",
    "        if label[i] > 0.5:\n",
    "            label[i] = 1 - label[i]\n",
    "\n",
    "    #4 bit mbti     \n",
    "    teacherpersonality = np.random.randint(low = 0, high = 2, size = (4))    \n",
    "    studentpersonality = np.random.randint(low = 0, high = 2, size = (4))\n",
    "    crosspersonality = 1 - np.bitwise_xor(teacherpersonality, studentpersonality)\n",
    "    \n",
    "    bitcount = np.sum(crosspersonality)\n",
    "    label = label + ((bitcount / 4 - 0.5) * 0.1)\n",
    "\n",
    "    #4 interest choices: music/art, sports, academic, humanities\n",
    "    #first 2 affect labels equally, second 2 affect only the scores for each subject\n",
    "    teacheractivities = np.random.randint(low = 0, high = 11, size = (4))\n",
    "    studentactivities = np.random.randint(low = 0, high = 11, size = (4))\n",
    "    crossactivities = np.multiply(teacheractivities, studentactivities)\n",
    "    \n",
    "    for i in range(output_size):\n",
    "        label[i] = label[i] + ((crossactivities[0] + crossactivities[1]) / 200 - 0.5) * 0.1\n",
    "        if(i < 4):\n",
    "            label[i] = label[i] + (crossactivities[2] / 100 - 0.5) * 0.1\n",
    "        else:\n",
    "            label[i] = label[i] + (crossactivities[3] / 100 - 0.5) * 0.1\n",
    "    \n",
    "    \n",
    "    #need to normalise labels to 0 to 1.\n",
    "    label = (label - np.min(label, axis = 0)) / (np.max(label, axis = 0) - np.min(label, axis = 0))\n",
    "    \n",
    "    \n",
    "    return np.concatenate((scoresdiff, crosspersonality, crossactivities, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = np.array([dataMaker() for i in range(test_data_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = keras.Input(shape=(input_size,), name=\"inputs\")\n",
    "# x = layers.Dense(20,activation='relu', name='Hidden1') (inputs)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden2') (x)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden3') (x)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden4') (x)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden5') (x)\n",
    "# outputs = layers.Dense(output_size, activation=\"relu\", name=\"predictions\")(x)\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(input_size,), name=\"inputs\"))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(output_size, activation=\"relu\", name=\"predictions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = my_data[:,:input_size]\n",
    "x_train = (x_train - np.average(x_train, axis = 0))/np.std(x_train, axis = 0)\n",
    "y_train = my_data[:,input_size:]\n",
    "x_val = x_train[(int)((1-test_frac)*test_data_size):]\n",
    "y_val = y_train[(int)((1-test_frac)*test_data_size):]\n",
    "x_train = x_train[:(int)((1-test_frac)*test_data_size)]\n",
    "y_train = y_train[:(int)((1-test_frac)*test_data_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.mean_squared_error,\n",
    "    metrics = [keras.metrics.mean_squared_error]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.4194 - mean_squared_error: 0.4194 - val_loss: 0.4105 - val_mean_squared_error: 0.4105\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3650 - mean_squared_error: 0.3650 - val_loss: 0.3640 - val_mean_squared_error: 0.3640\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.3327 - val_mean_squared_error: 0.3327\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3017 - mean_squared_error: 0.3017 - val_loss: 0.3075 - val_mean_squared_error: 0.3075\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2798 - mean_squared_error: 0.2798 - val_loss: 0.2864 - val_mean_squared_error: 0.2864\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2607 - mean_squared_error: 0.2607 - val_loss: 0.2679 - val_mean_squared_error: 0.2679\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2429 - mean_squared_error: 0.2429 - val_loss: 0.2520 - val_mean_squared_error: 0.2520\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2259 - mean_squared_error: 0.2259 - val_loss: 0.2363 - val_mean_squared_error: 0.2363\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2096 - mean_squared_error: 0.2096 - val_loss: 0.2225 - val_mean_squared_error: 0.2225\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1945 - mean_squared_error: 0.1945 - val_loss: 0.2078 - val_mean_squared_error: 0.2078\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1797 - mean_squared_error: 0.1797 - val_loss: 0.1937 - val_mean_squared_error: 0.1937\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1815 - val_mean_squared_error: 0.1815\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1540 - mean_squared_error: 0.1540 - val_loss: 0.1695 - val_mean_squared_error: 0.1695\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1581 - val_mean_squared_error: 0.1581\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1310 - mean_squared_error: 0.1310 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1205 - mean_squared_error: 0.1205 - val_loss: 0.1342 - val_mean_squared_error: 0.1342\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1116 - mean_squared_error: 0.1116 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1036 - mean_squared_error: 0.1036 - val_loss: 0.1155 - val_mean_squared_error: 0.1155\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0964 - mean_squared_error: 0.0964 - val_loss: 0.1078 - val_mean_squared_error: 0.1078\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0900 - mean_squared_error: 0.0900 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0841 - mean_squared_error: 0.0841 - val_loss: 0.0949 - val_mean_squared_error: 0.0949\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0787 - mean_squared_error: 0.0787 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0742 - mean_squared_error: 0.0742 - val_loss: 0.0840 - val_mean_squared_error: 0.0840\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0701 - mean_squared_error: 0.0701 - val_loss: 0.0794 - val_mean_squared_error: 0.0794\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - mean_squared_error: 0.0664 - val_loss: 0.0753 - val_mean_squared_error: 0.0753\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0632 - mean_squared_error: 0.0632 - val_loss: 0.0718 - val_mean_squared_error: 0.0718\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0603 - mean_squared_error: 0.0603 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0577 - mean_squared_error: 0.0577 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0553 - mean_squared_error: 0.0553 - val_loss: 0.0633 - val_mean_squared_error: 0.0633\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0532 - mean_squared_error: 0.0532 - val_loss: 0.0610 - val_mean_squared_error: 0.0610\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0513 - mean_squared_error: 0.0513 - val_loss: 0.0590 - val_mean_squared_error: 0.0590\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0494 - mean_squared_error: 0.0494 - val_loss: 0.0571 - val_mean_squared_error: 0.0571\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0551 - val_mean_squared_error: 0.0551\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0447 - mean_squared_error: 0.0447 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0433 - mean_squared_error: 0.0433 - val_loss: 0.0505 - val_mean_squared_error: 0.0505\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0409 - mean_squared_error: 0.0409 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0404 - val_mean_squared_error: 0.0404\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0386 - val_mean_squared_error: 0.0386\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0339 - val_mean_squared_error: 0.0339\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0325 - val_mean_squared_error: 0.0325\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0301 - val_mean_squared_error: 0.0301\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0284 - val_mean_squared_error: 0.0284\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0275 - val_mean_squared_error: 0.0275\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0263 - val_mean_squared_error: 0.0263\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0250 - val_mean_squared_error: 0.0250\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0243 - val_mean_squared_error: 0.0243\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0239 - val_mean_squared_error: 0.0239\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0235 - val_mean_squared_error: 0.0235\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history\n",
    "epochs = history.epoch\n",
    "hist = pd.DataFrame(history.history)\n",
    "mse = hist[\"mean_squared_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_loss_curve(epochs, mse):\n",
    "    \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, mse, label=\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "    plt.show()  \n",
    "\n",
    "    print(\"Defined the plot_the_loss_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "plot_the_loss_curve(epochs, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DA69B0D040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[0.56250304 0.7462276  0.6358173  0.         0.6474911  0.99915594\n",
      " 0.5892062  0.56027275]\n",
      "[0.65313189 0.9757633  0.65313189 0.         0.78753541 1.\n",
      " 0.71671388 0.62228517]\n",
      "[0.48573166 0.08050445 1.1047118  0.502877   0.38720715 1.0316987\n",
      " 0.48147285 0.68172616]\n",
      "[0.52773687 0.         0.92047128 0.60137457 0.52135493 0.86499755\n",
      " 0.50908198 1.        ]\n",
      "[0.02801792 0.197655   0.61797655 0.66362786 0.5881069  0.6048393\n",
      " 0.8897588  0.60019517]\n",
      "[0.         0.11148272 0.91044221 0.63173541 0.61910071 0.62839093\n",
      " 1.         0.55406912]\n",
      "[0.50286967 0.56175154 0.5744456  0.9266162  0.47450566 0.66763747\n",
      " 0.4313546  0.        ]\n",
      "[0.69958693 0.69958693 0.78407811 1.         0.61021404 0.93879084\n",
      " 0.60082614 0.        ]\n",
      "[0.79084796 0.5061163  0.73106897 0.274364   1.231976   0.93665516\n",
      " 0.03039084 0.380108  ]\n",
      "[0.59516779 0.3938255  0.90389262 0.15892617 0.79194631 1.\n",
      " 0.         0.20134228]\n",
      "[0.         0.11816159 0.4037368  1.0654367  1.0884458  1.0801872\n",
      " 0.4418733  0.56685346]\n",
      "[0.         0.09322034 0.53389831 1.         0.8959322  0.99762712\n",
      " 0.59084746 0.60779661]\n",
      "[0.56352854 0.5571616  0.04566565 0.8539673  0.         0.8854556\n",
      " 0.72668374 0.61100763]\n",
      "[0.52510067 0.51167785 0.21637584 0.92778523 0.         1.\n",
      " 0.77852349 0.66442953]\n",
      "[0.         0.74826354 0.41152924 0.8399606  0.49476767 0.\n",
      " 1.0239271  1.0001494 ]\n",
      "[0.         0.54809052 0.4184347  0.64827911 0.47548326 0.02168788\n",
      " 1.         0.98231966]\n",
      "[1.1870996  0.5641948  0.         0.24794456 0.8791939  0.43159384\n",
      " 0.7089834  0.5533142 ]\n",
      "[0.83939564 0.49664242 0.         0.41969782 1.         0.39843313\n",
      " 0.67823167 0.65025182]\n",
      "[0.6298991  0.21994205 0.92862236 0.69174373 1.0801266  0.54932296\n",
      " 0.53778094 0.        ]\n",
      "[0.66169327 0.21061763 1.         0.6703678  0.93684941 0.64191534\n",
      " 0.60721721 0.        ]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_train[:10])\n",
    "for i in range(10):\n",
    "    print(predictions[i])\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"compatModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\leeji\\AppData\\Local\\Temp\\tmpd0eq2hgv\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('compatModel.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
